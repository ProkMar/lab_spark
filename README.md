# lab_spark
Лабораторная работа по spark
Домашнее задание
Сборка витрины на PySpark

Цель:
В этом задании предлагается собрать статистику по криминогенной обстановке в разных районах Бостона. В качестве исходных данных используется датасет https://www.kaggle.com/AnalyzeBoston/crimes-in-boston

Цель задания - разработать прогрумму построения витирины.
Результат - ссылка на репозиторий с кодом.

Программа должна запускаться через spark-submit.
Пути к данным и к результату должны передаваться в качестве аргументов вызова.

Инструкция:

Загрузить данные.
Проверить данные на корректность, наличие дубликатов. Очистить.
Собрать витрину (агрегат по районам (поле district)) со следующими метриками:
crimes_total - общее количество преступлений в этом районе
crimes_monthly - медиана числа преступлений в месяц в этом районе
frequent_crime_types - три самых частых crime_type за всю историю наблюдений в этом районе, объединенных через запятую с одним пробелом “, ” , расположенных в порядке убывания частоты
crime_type - первая часть NAME из таблицы offense_codes, разбитого по разделителю “-” (например, если NAME “BURGLARY - COMMERICAL - ATTEMPT”, то crime_type “BURGLARY”)
lat - широта координаты района, расчитанная как среднее по всем широтам инцидентов
lng - долгота координаты района, расчитанная как среднее по всем долготам инцидентов
Сохранить витрину в один файл в формате .parquet в папке path/to/output_folder.
Подсказки: 

Функция percentile_approx может посчитать медиану.
Конкретный месяц идентифицируется не только номером месяца, но и номером года.
В справочнике кодов есть дубликаты. Нужно выбрать уникальные коды, взяв любое из названий.
